{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 Part 2 Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from numpy.matlib import repmat\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "**Consider the i.i.d. data samples $\\{x_i\\}_{i=1}^N$. Suppose that the data samples are drawn from a Geometric distribution with parameter $\\mu$. The Geometric distribution takes the form**\n",
    "\n",
    "$$p(x|\\mu) = (1-\\mu)^{x-1}\\mu$$\n",
    "\n",
    "**Answer the following questions:**\n",
    "\n",
    "1. **Find the MLE estimate for the parameter $\\mu$ assuming a Geometric data likelihood.**\n",
    "\n",
    "2. **Assuming a Beta distribution as the prior distribution on the parameter $\\mu$, find the MAP estimate for the parameter $\\mu$. The Beta distribution takes the form** \n",
    "\n",
    "$$\\text{Beta}(x|\\alpha,\\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1-x)^{\\beta-1}$$\n",
    "\n",
    "**where $\\Gamma(x) = (x-1)!$ and $\\alpha,\\beta>0$.**\n",
    "\n",
    "**Show your work.** \n",
    "\n",
    "***Note: there is no need to type your answer using LaTeX. Answer this question on paper and then upload a picture/scan of your work.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE\n",
    "\n",
    "The data likelihood is given by:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L} &= \\prod_{i=1}^N p(x_i|\\lambda)\\\\ \n",
    "&= \\prod_{i=1}^N (1-\\mu)^{x_i-1}\\mu\n",
    "\\end{align*}\n",
    "\n",
    "The log-data likelihood is then given by:\n",
    "\n",
    "\\begin{align*}\n",
    "\\ln \\mathcal{L} &= \\ln \\left( \\prod_{i=1}^N (1-\\mu)^{x_i-1}\\mu \\right) \\\\\n",
    "&= \\sum_{i=1}^N \\left((x_i-1)\\ln(1-\\mu) + ln(\\mu)\\right) \\\\\n",
    "&= \\sum_{i=1}^N (x_i-1)\\ln(1-\\mu) + N\\ln(\\mu)\n",
    "\\end{align*}\n",
    "\n",
    "Let's find the parameter $\\mu$ that maximizies the log-data likelihood:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\ln \\mathcal{L}}{\\partial \\lambda} &= 0 \\\\\n",
    "\\sum_{i=1}^N -\\frac{x_i-1}{1-\\mu} + \\frac{N}{\\mu} &= 0 \\\\\n",
    "\\sum_{i=1}^N -\\mu(x_i-1) + (1-\\mu)N &=0 \\\\\n",
    "-\\mu \\sum_{i=1}^N x_i + N\\mu + N - \\mu N &=0\\\\\n",
    "\\mu &= \\frac{N}{\\sum_{i=1}^N x_i}\n",
    "\\end{align*}\n",
    "\n",
    "## MAP\n",
    "\n",
    "The data likelihood is given by:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L} &= \\prod_{i=1}^N p(x_i|\\mu)p(\\mu|\\alpha,\\beta)\\\\ \n",
    "&= \\prod_{i=1}^N \\left( (1-\\mu)^{x_i-1}\\mu \\right) \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1}\n",
    "\\end{align*}\n",
    "\n",
    "The log-data likelihood is then given by:\n",
    "\n",
    "\\begin{align*}\n",
    "\\ln \\mathcal{L} &= \\ln \\left( \\prod_{i=1}^N \\left( (1-\\mu)^{x_i-1}\\mu \\right) \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1} \\right) \\\\\n",
    "&= \\sum_{i=1}^N \\left((x_i-1) \\ln(1-\\mu) +\\ln(\\mu) \\right) + \\ln\\left(\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\right) + (\\alpha-1)\\ln(\\mu) + (\\beta-1)\\ln(1-\\mu)\\\\\n",
    "&= \\left(\\sum_{i=1}^N x_i -N +\\beta-1\\right) \\ln(1-\\mu) + \\left(N+\\alpha-1\\right)\\ln(\\mu)\n",
    "\\end{align*}\n",
    "\n",
    "Let's find the parameter $\\mu$ that maximizies the log-data likelihood:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\ln \\mathcal{L}}{\\partial \\lambda} &= 0 \\\\\n",
    "-\\left(\\sum_{i=1}^N x_i -N +\\beta-1\\right)\\mu + \\left(N+\\alpha-1\\right)(1-\\mu) &= 0 \\\\\n",
    "\\mu &= \\frac{N+\\alpha-1}{\\sum_{i=1}^N x_i +\\beta+\\alpha-2}\n",
    "\\end{align*}\n",
    "\n",
    "And so, the parameter $\\mu$ that maximizes the log-data likelihood is a function of both the data $\\mathbf{x}$ and the prior parameters, $\\alpha$ and $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "## Crab Dataset Description\n",
    "\n",
    "**The Crab Data Set has 200 samples and 7 features (Frontal Lip, Rear Width, Length, Width, Depth, Male and Female), describing 5 morphological measurements on 50 crabs each of two color forms and both sexes, of the species *Leptograpsus* variegatus collected at Fremantle, W. Australia.**\n",
    "\n",
    "* **Dataset Source: Campbell, N.A. and Mahon, R.J. (1974) A multivariate study of variation in two species of rock crab of genus *Leptograpsus*. *Australian Journal of Zoology* 22, 417â€“425.**\n",
    "\n",
    "**The data set is saved in the file \"crab.txt\": the firt column corresponds to the class label (crab species) and the other 7 columns correspond to the features.**\n",
    "\n",
    "**Use the first 140 samples as your training set and the last 60 samples as your test set.**\n",
    "\n",
    "**Answer the following questions:**\n",
    "\n",
    "1. **Implement the Naive Bayes classifier, under the assumption that your data likelihood model $p(x|C_j)$ is a multivariate Gaussian and the prior probabilities $p(C_j)$ are dictated by the number of samples $n_j\\in\\mathbb{R}$ that you have for each class.**\n",
    "\n",
    "2. **Did you encounter any problems when implementing the probabilistic generative model? What is your solution for the problem? Explain why your solution works. (Note: There is more than one solution.)**\n",
    "\n",
    "3. **Report your classification results in terms of a confusion matrix in both training and test set. (You can use the function ```confusion_matrix``` from the module ```sklearn.metrics```.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>FrontalLip</th>\n",
       "      <th>RearWidth</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>14.4</td>\n",
       "      <td>42.8</td>\n",
       "      <td>46.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.3</td>\n",
       "      <td>11.1</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32.3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>14.3</td>\n",
       "      <td>32.3</td>\n",
       "      <td>37.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>20.4</td>\n",
       "      <td>23.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>14.1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Species  FrontalLip  RearWidth  Length  Width  Depth  Male  Female\n",
       "0        0        20.6       14.4    42.8   46.5   19.6     1       0\n",
       "1        1        13.3       11.1    27.8   32.3   11.3     1       0\n",
       "2        0        16.7       14.3    32.3   37.0   14.7     0       1\n",
       "3        1         9.8        8.9    20.4   23.9    8.8     0       1\n",
       "4        0        15.6       14.1    31.0   34.5   13.8     0       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"crab.txt\", delimiter=\"\\t\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 7), (60, 7), (140,), (60,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data.iloc[:140,1:].to_numpy()\n",
    "y_train = data.iloc[:140,0].to_numpy()\n",
    "\n",
    "X_test = data.iloc[140:,1:].to_numpy()\n",
    "y_test = data.iloc[140:,0].to_numpy()\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Generative Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5142857142857142, 0.4857142857142857)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prior probabilities\n",
    "\n",
    "pC0 = np.sum(y_train==0)/y_train.size\n",
    "pC1 = np.sum(y_train==1)/y_train.size\n",
    "\n",
    "pC0, pC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means and covariances of the data likelihood\n",
    "\n",
    "mu0 = np.mean(X_train[y_train==0,:],axis=0)\n",
    "mu1 = np.mean(X_train[y_train==1,:],axis=0)\n",
    "\n",
    "cov0 = np.cov(X_train[y_train==0,:].T)\n",
    "cov1 = np.cov(X_train[y_train==1,:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-db01776bee83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Training Data Likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my0_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmu0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcov0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#P(x|C0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my1_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmu1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcov1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#P(x|C1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Test Data Likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36mpdf\u001b[1;34m(self, x, mean, cov, allow_singular)\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_quantiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m         \u001b[0mpsd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_PSD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_singular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpsd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpsd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_pdet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpsd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_squeeze_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, M, cond, rcond, lower, check_finite, allow_singular)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_singular\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'singular matrix'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m         \u001b[0ms_pinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pinv_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_pinv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: singular matrix"
     ]
    }
   ],
   "source": [
    "# Training Data Likelihood\n",
    "y0_train = multivariate_normal.pdf(X_train, mean=mu0, cov=cov0) #P(x|C0)\n",
    "y1_train = multivariate_normal.pdf(X_train, mean=mu1, cov=cov1) #P(x|C1)\n",
    "\n",
    "# Test Data Likelihood\n",
    "y0_test = multivariate_normal.pdf(X_test, mean=mu0, cov=cov0) #P(x|C0)\n",
    "y1_test = multivariate_normal.pdf(X_test, mean=mu1, cov=cov1) #P(x|C1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we used all 7 features, the covariance matrix $\\Sigma_X$ would be singular. This is because one of the features is colinear with another feature. In particular, features male and female and the negative of one another.\n",
    "\n",
    "There are 2 ways to address this issue:\n",
    "\n",
    "1. Eliminate one of the features (method used here)\n",
    "2. Diagonally-load the covariance matrix: $\\Sigma_X + \\lambda I$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 6), (60, 6), (140,), (60,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminating the last feature (\"female\")\n",
    "\n",
    "X_train = data.iloc[:140,1:7].to_numpy()\n",
    "X_test = data.iloc[140:,1:7].to_numpy()\n",
    "y_train = data.iloc[:140,0].to_numpy()\n",
    "y_test = data.iloc[140:,0].to_numpy()\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recomputing MLE estimates for mean and covariance\n",
    "\n",
    "mu0 = np.mean(X_train[y_train==0,:],axis=0)\n",
    "mu1 = np.mean(X_train[y_train==1,:],axis=0)\n",
    "\n",
    "cov0 = np.cov(X_train[y_train==0,:].T)\n",
    "cov1 = np.cov(X_train[y_train==1,:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140,), (140,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data Likelihood\n",
    "y0_train = multivariate_normal.pdf(X_train, mean=mu0, cov=cov0) #P(x|C0)\n",
    "y1_train = multivariate_normal.pdf(X_train, mean=mu1, cov=cov1) #P(x|C1)\n",
    "\n",
    "# Test Data Likelihood\n",
    "y0_test = multivariate_normal.pdf(X_test, mean=mu0, cov=cov0) #P(x|C0)\n",
    "y1_test = multivariate_normal.pdf(X_test, mean=mu1, cov=cov1) #P(x|C1)\n",
    "\n",
    "y0_train.shape, y1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior for Training Data\n",
    "pos0_train = (y0_train*pC0)/(y0_train*pC0 + y1_train*pC1) # Class 0\n",
    "pos1_train = (y1_train*pC1)/(y0_train*pC0 + y1_train*pC1) # Class 1\n",
    "pos_train = np.array([pos0_train, pos1_train]).T # Creating a matrix with posterior probabilities\n",
    "likelihood_train = np.array([y0_train, y1_train]).T # Creating a matrix with likelihoods\n",
    "\n",
    "# Posterior for Test Data\n",
    "pos0_test = (y0_test*pC0)/(y0_test*pC0 + y1_test*pC1) # Class 0\n",
    "pos1_test = (y1_test*pC1)/(y0_test*pC0 + y1_test*pC1) # Class 1\n",
    "pos_test = np.array([pos0_test, pos1_test]).T # Creating a matrix with posterior probabilities\n",
    "likelihood_test = np.array([y0_test, y1_test]).T # Creating a matrix with likelihoods\n",
    "\n",
    "# Prediction for Training Data\n",
    "predict_train = np.argmax(pos_train, axis=1) # Label prediction for training data\n",
    "# labels it as the class with largest posterior\n",
    "predict_likelihood_train = likelihood_train[predict_train] # Likelihood value for the assigned class\n",
    "\n",
    "# Prediction for Test Data\n",
    "predict_test = np.argmax(pos_test, axis=1) # Label prediction for test set\n",
    "predict_likelihood_test = likelihood_train[predict_test] # Likelihood value for the assigned class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix in Training\n",
      "[[72  0]\n",
      " [ 0 68]]\n",
      "Confusion matrix in Test\n",
      "[[28  0]\n",
      " [ 0 32]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix in Training')\n",
    "print(confusion_matrix(y_train, predict_train))\n",
    "\n",
    "print('Confusion matrix in Test')\n",
    "print(confusion_matrix(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows that all points were correctly classified for both training and test sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
