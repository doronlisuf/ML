{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 24 - Clustering Validity Measures; Non-parametric Generative Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Validity Metrics\n",
    "\n",
    "How would you evaluate clustering results? - **Cluster Validity Indices**\n",
    "    \n",
    "* Cluster validity indices are used for a number of different goals. For example, cluster validity metrics can be used to compare clustering results, try to determine the *correct* number of clusters, try to select the *correct* parameter settings, try to evaluate the approppriateness of the clustering result based on the data only (and not using another result or \"ground truth\" data).\n",
    "    \n",
    "In general, there are three types of **index criteria** to perform cluster validity:\n",
    "\n",
    "1. **Internal criteria.** We evaluate the results of a clustering algorithm in terms of quantities that involve the vectors of the data set themselves. \n",
    "2. **External criteria.** We evaluate the results of a clustering algorithm based on a pre-specified structure, which is imposed on a data set and reflects our intuition about the clustering structure of the data set.\n",
    "3. **Relative criteria.** We evaluate the results of a clustering structure by comparing it to other clustering schemes, resulting by the same algorithm but with different parameter values. In practice, relative criteria are a combination on internal and external criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal Criteria \n",
    "\n",
    "As the goal of clustering is to make objects within the same cluster similar and objects in different clusters distinct, internal cluster validity measures are defined by combining compactness and separability.\n",
    "\n",
    "The optimal clustering scheme under the internal criteria index includes:\n",
    "\n",
    "* Compactness (or intra-distance or within-cluster scatter): The members of each cluster should be as close to each other as possible. A common measure of compactness is the variance, which should be minimized.\n",
    "* Separation (or inter-distance or between-cluster scatter): This indicates how distinct two clusters are. It computes the distance between two different clusters. There are three common approaches measuring the distance between two different clusters:\n",
    "    * Single linkage: It measures the distance between the closest members of the clusters. \n",
    "    * Complete linkage: It measures the distance between the most distant members. \n",
    "    * Comparison of centroids: It measures the distance between the centers of the clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Silhouette Index\n",
    "\n",
    "The Silhoute Index is an internal cluster validity index that is used to judge the quality of any clustering solution. \n",
    "\n",
    "Given a set of data points $X=\\{x_1,\\dots,x_N\\}$ and a partition of $X$ (i.e. clustering result). Let's define the following:\n",
    "* $a_i$ is the average distance of the point $x_i$ to all the other points of the cluster in which $x_i$ is assigned to\n",
    "* $b_i$ is the average distance of the point $x_i$ to all the other points of in the other clusters. \n",
    "\n",
    "For every data point $x_i \\in X$, the Silhouette Index is defined as:\n",
    "\n",
    "$$s = \\frac{1}{N} \\sum_{i=1}^N \\frac{b_i-a_i}{\\max(a_i,b_i)}$$\n",
    "\n",
    "* Silhouette index is the average silhouette of all data points and it reflects the compactness and separation of clusters.\n",
    "\n",
    "* The value of silhouette index varies from -1 and 1 and higher indicates better clustering results.\n",
    "\n",
    "There are many other internal cluster validity indices!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Criteria\n",
    "\n",
    "External cluster validity indices are used to measure how well a clustering result matches a set of *give* labels. \n",
    "External cluster validity indices can be used to:\n",
    "* compare the clustering results with the *ground truth* (true labels),\n",
    "* compare clustering results between different clustering algorithms to measure how different they are and how stable a particular clustering is on a data set across parameter settings and/or algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Rand Index\n",
    "\n",
    "The Rand Index is an external cluster validity index that is used to compare clustering results obtained from different parameter settings or algorithms. \n",
    "\n",
    "Given a set of data points $X$ and two partitions (i.e. clustering results) of $X$ to compare. One partition $C=\\{C_1, \\dots,C_k\\}$, that partitions $X$ into $k$ clusters, and another partition $D=\\{D_1,\\dots,D_s\\}$, that partitions $X$ into $s$ clusters. Let's define the following:\n",
    "\n",
    "* $a$ is the number of pairs of elements in $X$ that are in the same subset in $C$ and in the same subset in $D$.\n",
    "* $b$ is the number of pairs of elements in $X$ that are in different subset in $C$ and in different subset in $D$.\n",
    "* $c$ is the number of pairs of elements in $X$ that are in the same subset in $C$ and in different subset in $D$.\n",
    "* $d$ is the number of pairs of elements in $X$ that are in different subset in $C$ and in the same subset in $D$.\n",
    "\n",
    "The Rand Index is defined as:\n",
    "\n",
    "$$r = \\frac{a+b}{a+b+c+d}$$\n",
    "\n",
    "* Intuitively, $a+b$ can be considered as the number of *agreements* between $C$ and $D$, and $c+d$ as the number of *disagreements* between $C$ and $D$.\n",
    "\n",
    "* The value of rand index varies from 0 and 1 and higher indicates higher consistency between partitions $C$ and $D$.\n",
    "\n",
    "There are many other external cluster validity indices!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-parametric Generative Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have introduced the probabilistic generative classifier, and, as we discussed, the probabilistic generative classifier requires us to assume a parametric form for each class (e.g., each class is represented by a multivarite Gaussian distribution, etc.). Because of this, the probabilistic generative classifier is a *parametric* approach.\n",
    "\n",
    "* Parametric approaches have the drawback that the functional parametric form needs to be decided/assumed in advance and, if chosen poorly, might a poor model of the distribution that generates the data resulting in poor performance.\n",
    "\n",
    "**Non-parametric methods** are those that do not assume a particular generating distribution for the data. The **K-nearest nerighbors (K-NN)** algorithm is one example of a non-parametric classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Classifier\n",
    "\n",
    "Nearest neighbors methods compare a test point to the $k$ nearest training data points and then estimate an output value based on the desired/true output values of the $k$ nearest training points.\n",
    "\n",
    "* Essentially, there is no \"training\" other than storing the training data points and their desired outputs\n",
    "\n",
    "* In test, you need to: \n",
    "    1. Determine which $k$ neighbors in the training data are closest to the test point; and,\n",
    "    2. Determine the output value for the test point.\n",
    "    \n",
    "In order to find the $k$ *nearest-neighbors* in the training data, you need to define a **similarity measure** or a **dissimilarity measure**. The most common dissimilarity measure is Euclidean distrance:\n",
    "\n",
    "* Euclidean distance: $d_E(\\mathbf{x}_1, \\mathbf{x}_2) = \\sqrt{(\\mathbf{x}_1 - \\mathbf{x}_2)^T(\\mathbf{x}_1 - \\mathbf{x}_2)}$\n",
    "\n",
    "* City-block distance: $d_{CB}(\\mathbf{x}_1,\\mathbf{x}_2) = \\sum_{i=1}^n |\\mathbf{x}_{1i} - \\mathbf{x}_{2i}|$\n",
    "\n",
    "* Mahalanobis distance: $d_M(\\mathbf{x}_1, \\mathbf{x}_2) = \\sqrt{(\\mathbf{x}_1 - \\mathbf{x}_2)^T\\Sigma^{-1}(\\mathbf{x}_1 - \\mathbf{x}_2)}$\n",
    "\n",
    "* Cosine angle similarity: $\\cos(\\theta) = \\frac{\\mathbf{x}_1^T \\mathbf{x}_2}{\\Vert\\mathbf{x}_1\\Vert_2^2 \\Vert\\mathbf{x}_2\\Vert_2^2}$\n",
    "\n",
    "* and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are doing classification, once you find the $k$ nearest neighbors to your test point in the training data, then you can determine the class label of your test point using (most commonly) **majority vote**.\n",
    "\n",
    "* If there are ties, they can be broken randomly or using schemes like applying the label to the closest data point in the neighborhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussions\n",
    "\n",
    "1. What happens when there are imbalanced classes?\n",
    "\n",
    "2. Is k-NN sensitive to data scaling?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
