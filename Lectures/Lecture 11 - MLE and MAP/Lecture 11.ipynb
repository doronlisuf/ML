{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 11 - Maximum Likelihood Estimation (MLE) & Maximum A Posteriori (MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last class, we introduced the **Bayesian interpretation** of a supervised learning algorithm, and formulated two approaches for search for parameters of the model:\n",
    "\n",
    "1. **Maximum Likelihood Estimation (MLE)**\n",
    "\n",
    "2. **Maximum A Posteriori (MAP)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our problem, the hypothesis are the *unknown* **(hyper-)parameters** $\\mathbf{w}$.\n",
    "\n",
    "* In Bayesian statistics (MAP), we are then trying to find the $\\mathbf{w}$'s that maximizing the posterior probability.\n",
    "* In classical statistics (MLE), on the other hand, we are only computing the probability of some hypothesis (the *null hypothesis*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<h2 align=\"center\"><span style=\"color:blue\">Maximum Likelihood Estimation (MLE)</span></h2>\n",
    "<center>(Frequentist approach)</center>\n",
    "\n",
    "$$\\arg_{\\mathbf{w}} \\max P(\\mathbf{t}|\\mathbf{w})$$\n",
    "\n",
    "In **Maximum Likelihood Estimation** (also referred to as **MLE** or **ML**) we want to *find the set of parameters* that **maximize** the data likelihood $P(\\mathbf{t}|\\mathbf{w})$. We want to find the *optimal* set of parameters under some assumed distribution such that the data is most likely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<h2 align=\"center\"><span style=\"color:orange\">Maximum A Posteriori (MAP)</span></h2>\n",
    "<center>(Bayesian approach)</center>\n",
    "\n",
    "\\begin{align}\n",
    "& \\arg_{\\mathbf{w}} \\max P(\\mathbf{t}|\\mathbf{w})P(\\mathbf{w}) \\\\ \n",
    "& \\propto \\arg_{\\mathbf{w}} \\max P(\\mathbf{w}|\\mathbf{t})\n",
    "\\end{align}\n",
    "\n",
    "In **Maximum A Posteriori** (also referred as **MAP**) we want to *find the set of parameters* that **maximize** the posteriori probability $P(\\mathbf{w}|\\mathbf{t})$. We want to find the *optimal* set of parameters under some assumed distribution such that the parameters are most likely to have been drawn off of given some prior beliefs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-4,4,1000)\n",
    "Gaussian = np.exp(-x**2/2)/np.sqrt(2*np.pi) #Gaussian with zero-mean and unit-variance\n",
    "Laplacian = np.exp(-np.abs(x))/(2) #Laplacian with zero-mean and lambda=1\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(x, Gaussian, '--', label='Gaussian, $G(0,1)$')\n",
    "plt.plot(x, Laplacian, label='Laplacian, $L(0,1)$')\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "plt.xlabel('$w$', size=15)\n",
    "plt.ylabel('Prior Probability\\n$P(w)$', size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Least Squares objective function in our regression problem, we showed that:\n",
    "\n",
    "* If we do not use a regularization term, then we are performing MLE. We are maximizing the data likelihood which takes the form of a Gaussian distribution.\n",
    "\n",
    "* If we use a regularization term, then we are performing MAP. We are maximizing the posterior distribution, which is equivalent at maximizing the data likelihood times the prior probability on the parameters.\n",
    "    * If we use *ridge regularizer*, both data likelihood and prior distribution take the form of a Gaussian.\n",
    "    * If we use *lasso regularizer*, data likelihood takes the form of a Gaussian distribution and the prior takes the form of a Laplacian distribution.\n",
    "    \n",
    "    \n",
    "Furthermore, this Bayesian interpretation allows us to think of a problem in a different way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **What is the distribution form of the error values for our model?**\n",
    "\n",
    "* **Why is it so common to assume Gaussian error distribution?** The reason why we always assume a Gaussian error distribution goes back an important result described by the Central Limit Theorem. The Central Limit Theorem says that whenever a measurement is subject to a very large number of very small errors, the probability distribution for the total error is driven toward the Gaussian distribution. This is true regardless of the form of the original probability distributions of the individual errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "**Problem: Suppose I flip a coin 3 times and observe the event H-H-H. What is the probability of flipping Heads (H) on the next coin flip?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's consider heads=1 and tails=0, so our sample space is $S=\\{1,0\\}$. The probability of heads is equal to some *unknown* value $\\mu$, then:\n",
    "\n",
    "\\begin{align}\n",
    "& P(x=1 | \\mu) = \\mu \\\\\n",
    "& P(x=0|\\mu) = 1-\\mu\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the data likelihood as:\n",
    "\n",
    "$$P(x|\\mu) = \\mu^x(1-\\mu)^{1-x} = \\begin{cases}\\mu & \\text{if }x=1 \\\\ 1-\\mu & \\text{if } x=0 \\end{cases}$$\n",
    "\n",
    "* This is the **Bernoulli distribution**. The mean and variance of the Bernoulli distribution are: $E[x] = \\mu$ and $E[\\left(x- E[x]\\right)^2] = \\mu(1-\\mu)$.\n",
    "\n",
    "* So, for every outcome of the event $E$, we will model it using a Bernoulli distribution, and each outcome is pairwise **conditionally independent**. Therefore, we have the event $E$ contains i.i.d. outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Maximum Likelihood Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity of calculation, assume that the event contains outcomes: $E=x_1\\cap x_2\\cap \\dots\\cap x_N$, where $x_i=\\{0,1\\}$ (0 for Tails and 1 for Heads). Then, for an experiment with $N$ samples, we can write the **data likelihood** as:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "P(E|\\mu) &= P(x_1\\cap x_2\\cap \\dots\\cap x_N|\\mu) \\\\\n",
    "&= P(x_1|\\mu)P(x_2|\\mu)\\dots P(x_N|\\mu) \\\\\n",
    "&= \\prod_{n=1}^N P(x_n|\\mu) \\\\\n",
    "&= \\prod_{n=1}^N \\mu^{x_n} (1-\\mu)^{1-x_n}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, we are interested in finding the value of $\\mu$ given some data set $E$. \n",
    "\n",
    "We now optimize the data likelihood. What trick can we use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$arg_\\mathbf{\\mu} \\max P(E|\\mu) = \\arg_\\mathbf{\\mu} \\max \\ln \\left( P(E|\\mu) \\right)$$\n",
    "\n",
    "because the $\\ln(\\bullet)$ is a monotonic function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where \n",
    "$$\\ln(P(E|\\mu) = \\sum_{n=1}^N \\left(x_n \\ln(\\mu) + (1-x_n)\\ln(1-\\mu)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can take the derivative of this function wrt to $\\mu$ and equal it to zero:\n",
    "\n",
    "$$\\frac{\\partial \\ln(P(E|\\mu))}{\\partial \\mu} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "(1-\\mu)\\sum_{n=1}^N x_n - \\mu \\left(N - \\sum_{n=1}^N x_n\\right) &= 0 \\\\\n",
    "\\sum_{n=1}^N x_n - \\mu\\sum_{n=1}^N x_n - \\mu N + \\mu\\sum_{n=1}^N x_n &= 0 \\\\\n",
    "\\sum_{n=1}^N x_n - \\mu N &= 0 \\\\\n",
    "\\mu &= \\frac{1}{N} \\sum_{n=1}^N x_n\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the MLE estimation of the probability of seeing heads in the next coin flip is equal to **relative frequency** of outcome heads.\n",
    "\n",
    "* Suppose you flipped the coin only once, and saw Tails. The probability of flipping Heads according to MLE would be 0.\n",
    "\n",
    "* MLE is **purely data driven**! This is sufficient *when* we have lots and lots of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Maximum A Posteriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the MAP estimation of $\\mu$, we are instead optimizing the posterior probability:\n",
    "\n",
    "\\begin{align}\n",
    "&\\arg_{\\mu} \\max P(\\mu|E) \\\\\n",
    "=& \\arg_{\\mu} \\max \\frac{P(E|\\mu) P(\\mu)}{P(E)} \\\\\n",
    "\\propto & \\text{  } \\arg_{\\mu} \\max P(E|\\mu) P(\\mu), P(E)\\text{ is some constant value} \n",
    "\\end{align}\n",
    "\n",
    "We have defined the data likelihood $P(E|\\mu)$, we now need to choose a **prior distribution** $P(\\mu)$.\n",
    "\n",
    "* This prior distribution will *encode* any prior knowledge we have about the hidden sate of the problem, in this case, the type of coin that was used.\n",
    "\n",
    "Let's say our **prior distribution** is a Beta Distribution. A **Beta Distribution** takes the form:\n",
    "\n",
    "$$\\text{Beta}(X|\\alpha,\\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1-x)^{\\beta-1}$$\n",
    "\n",
    "where $\\Gamma(x) = (x-1)!$ and $\\alpha,\\beta>0$.\n",
    "\n",
    "The mean and variance of the Beta distribution are: $E[x] = \\frac{\\alpha}{\\alpha+\\beta}$ and $E[(x-E[x])^2] = \\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's see what that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "a = 2\n",
    "b = 2\n",
    "x = np.arange(0,1,0.0001)\n",
    "Beta = (math.gamma(a+b)/(math.gamma(a)*math.gamma(b)))*x**(a-1)*(1-x)**(b-1)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(x, Beta, label='Beta Distribution, B('+str(a)+','+str(b)+')')\n",
    "plt.legend(loc='best',fontsize=15)\n",
    "plt.xlabel('Probability of Heads\\n$\\mu$',fontsize=15)\n",
    "plt.ylabel('Prior Probability\\n$P(\\mu)$',fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Beat Distribution as out prior, we have:\n",
    "\n",
    "\\begin{align}\n",
    "P(\\mu|\\alpha,\\beta) &= \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1} \\\\\n",
    "&\\propto \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let:\n",
    "* $m$ the number of heads\n",
    "* $l$ the number of tails\n",
    "* $N=m+l$ the total number of coin flips \n",
    "\n",
    "We can write our **posterior probability** as:\n",
    "\n",
    "\\begin{align}\n",
    "P(\\mu|E) &= \\frac{P(E|\\mu)P(\\mu)}{P(E)}\\\\\n",
    "&\\propto P(E|\\mu)P(\\mu)\\\\\n",
    "&= \\left(\\prod_{n=1}^N \\mu^{x_n} (1-\\mu)^{1-x_n}\\right) \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1} \\\\\n",
    "&= \\mu^m (1-\\mu)^l \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1} \\\\\n",
    "&= \\mu^{m+\\alpha-1} (1-\\mu)^{l+\\beta-1}\n",
    "\\end{align}\n",
    "\n",
    "* The posterior probability has the same shape as the data likelihood. \n",
    "\n",
    "* This is a special case called **Conjugate Prior Relationship**, which happens when the posterior has the same form as the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now optimize our posterior probability, and we will apply the same trick:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$arg_\\mathbf{\\mu} \\max P(\\mu|E) = \\arg_\\mathbf{\\mu} \\max \\ln \\left( P(\\mu|E) \\right)$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\ln \\left( P(\\mu|E) \\right) =  (m+\\alpha-1)\\ln(\\mu) + (l+\\beta-1)\\ln(1-\\mu)$$\n",
    "\n",
    "We can now *optimize* our posterior probability:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial  \\ln \\left( P(\\mu|E) \\right)}{\\partial \\mu} &= 0\\\\\n",
    "\\frac{m+\\alpha-1}{\\mu} + \\frac{l+\\beta-1}{1-\\mu} &= 0\\\\\n",
    "\\mu &= \\frac{m+\\alpha-1}{m + l + \\alpha + \\beta -2}\n",
    "\\end{align}\n",
    "\n",
    "This is our estimation of the probability of heads using MAP!\n",
    "\n",
    "* Our estimation for the probability of heads, $\\mu$, is going to depend on $\\alpha$ and $\\beta$ introduced by the prior distribution. We saw that they control the level of certainty as well as the center value.\n",
    "\n",
    "* With only a few samples, the prior will play a bigger role in the decision, but eventually the data takes over the prior.\n",
    "\n",
    "Let's run a simulation to compare MAP and MLE estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueMU = 0.5 # 0.5 for a fair coin\n",
    "Nflips = 10\n",
    "a = 2\n",
    "b = 10\n",
    "\n",
    "Outcomes = []\n",
    "for i in range(Nflips):\n",
    "    Outcomes += [stats.bernoulli(trueMU).rvs(1)[0]]\n",
    "    print(Outcomes)\n",
    "    print('MLE aka Frequentist Probability of Heads = ', np.sum(Outcomes)/len(Outcomes))\n",
    "    print('MAP aka Bayesian Probability of Heads = ', (np.sum(Outcomes)+a-1)/(len(Outcomes)+a+b-2))\n",
    "    input('Press enter to flip the coin again...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<h2 align=\"center\"><span style=\"color:blue\">Maximum Likelihood Estimation (MLE)</span></h2>\n",
    "<center>(Frequentist approach)</center>\n",
    "\n",
    "$$\\arg_{\\mathbf{w}} \\max P(\\mathbf{t}|\\mathbf{w})$$\n",
    "\n",
    "In **Maximum Likelihood Estimation** we *find the set of parameters* that **maximize** the data likelihood $P(\\mathbf{t}|\\mathbf{w})$. We find the *optimal* set of parameters under some assumed distribution such that the data is most likely.\n",
    "\n",
    "* MLE focuses on maximizing the data likelihood, which *usually* provides a pretty good estimate\n",
    "\n",
    "* A common trick to maximize the data likelihood is to maximize the log likelihood\n",
    "\n",
    "* MLE is purely data driven \n",
    "\n",
    "* MLE works best when we have lots and lots of data\n",
    "\n",
    "* MLE will likely overfit when we have small amounts of data or, at least, becomes unreliable\n",
    "\n",
    "* It estimates relative frequency for our model parameters. Therefore it needs incredibly large amounts of data (infinite!) to estimate the true likelihood parameters\n",
    "    * This is a problem when we want to make inferences and/or predictions outside the range of what the training data has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<h2 align=\"center\"><span style=\"color:orange\">Maximum A Posteriori (MAP)</span></h2>\n",
    "<center>(Bayesian approach)</center>\n",
    "\n",
    "\\begin{align}\n",
    "& \\arg_{\\mathbf{w}} \\max P(\\mathbf{t}|\\mathbf{w})P(\\mathbf{w}) \\\\ \n",
    "& \\propto \\arg_{\\mathbf{w}} \\max P(\\mathbf{w}|\\mathbf{t})\n",
    "\\end{align}\n",
    "\n",
    "In **Maximum A Posteriori** we *find the set of parameters* that **maximize** the the posterior probability $P(\\mathbf{w}|\\mathbf{t})$. We find the *optimal* set of parameters under some assumed distribution such that the parameters are most likely to have been drawn off of.\n",
    "\n",
    "* MAP focuses on maximizing the posterior probability - data  likelihood with a prior\n",
    "\n",
    "* A common trick to maximize the posterior probability is to maximize the log likelihood\n",
    "\n",
    "* MAP is data driven \n",
    "\n",
    "* MAP is mostly driven by the prior beliefs\n",
    "\n",
    "* MAP works great with small amounts of data *if* our prior was chosen well\n",
    "\n",
    "* We need to assume and select a distribution for our prior beliefs\n",
    "    * A wrong choice of prior distribution can impact negatively our model estimation\n",
    "    \n",
    "* When we have lots and lots of data, the data likelihood will take over and the posterior will depend less and less on the prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjugate Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Two distributions have a **conjugate prior** relationship when the form of the posterior is the same as the form of the prior.\n",
    "\n",
    "    * For example, consider the data likelihood $P(X|\\mu) \\sim \\mathcal{N}(\\mu, \\sigma^2)$ and the prior distribution $P(\\mu) \\sim \\mathcal{N}(\\mu_0,\\sigma_0^2)$. The posterior probability will also be Gaussian distributed\n",
    "    \n",
    "$$P(\\mu|X) \\sim \\mathcal{N}\\left(\\frac{\\sum_{i=1}^N x_i\\sigma_0^2 + \\mu_0\\sigma^2}{N\\sigma_0^2+\\sigma^2},\\left(\\frac{N}{\\sigma^2}+\\frac{1}{\\sigma_0^2}\\right)^{-1}\\right)$$\n",
    "\n",
    "<!-- Proof: \n",
    "\n",
    "\\begin{align}\n",
    "P(\\mu|X) &\\propto P(X|\\mu)P(\\mu) \\\\\n",
    "& = \\prod_{i=1}^N \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{1}{2}\\frac{(x_i-\\mu)^2}{\\sigma^2}\\right)\\frac{1}{\\sqrt{2\\pi\\sigma_0^2}}\\exp\\left(-\\frac{1}{2}\\frac{(\\mu-\\mu_0)^2}{\\sigma_0^2}\\right) \\\\\n",
    "&=  \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\frac{1}{\\sqrt{2\\pi\\sigma_0^2}}\\exp\\left(\\sum_{i=1}^N \\left(-\\frac{1}{2}\\frac{(x_i-\\mu)^2}{\\sigma^2}\\right) -\\frac{1}{2}\\frac{(\\mu-\\mu_0)^2}{\\sigma_0^2} \\right) \\\\\n",
    "&=  \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\frac{1}{\\sqrt{2\\pi\\sigma_0^2}}\\exp\\left(-\\frac{1}{2}\\left(\\sum_{i=1}^N \\frac{(x_i-\\mu)^2}{\\sigma^2} +\\frac{(\\mu-\\mu_0)^2}{\\sigma_0^2} \\right) \\right) \\\\\n",
    "&=  \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\frac{1}{\\sqrt{2\\pi\\sigma_0^2}}\\exp\\left(-\\frac{1}{2}\\left(\\frac{\\sum_{i=1}^N x_i^2-2\\sum_{i=1}^N x_i\\mu +\\mu^2N)}{\\sigma^2} +\\frac{\\mu^2-2\\mu\\mu_0 +\\mu_0^2}{\\sigma_0^2} \\right) \\right) \\\\\n",
    "&=  \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\frac{1}{\\sqrt{2\\pi\\sigma_0^2}}\\exp\\left(-\\frac{1}{2} \\left(\\frac{N}{\\sigma^2}+\\frac{1}{\\sigma_0^2}\\right) - 2\\mu \\left( \\frac{\\sum_{i=1}^N x_i}{\\sigma^2} + \\frac{\\mu_0}{\\sigma_0^2}\\right) + \\frac{\\sum_{i=1}^N x_i^2}{\\sigma^2} + \\frac{\\mu_0^2}{\\sigma_0^2}\\right) \\\\\n",
    "&=  \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\frac{1}{\\sqrt{2\\pi\\sigma_0^2}}\\exp\\left(-\\frac{1}{2} \\left(\\frac{N}{\\sigma^2}+\\frac{1}{\\sigma_0^2}\\right) \\left(\\mu^2 - 2\\mu\\left(\\frac{\\sum_{i=1}^N x_i}{\\sigma^2} + \\frac{\\mu_0}{\\sigma_0^2}\\right)\\left(\\frac{N}{\\sigma^2}+\\frac{1}{\\sigma_0^2}\\right)^{-1} \\right) \\right) \\exp\\left(\\frac{\\sum_{i=1}^N x_i}{\\sigma^2} + \\frac{\\mu_0^2}{\\sigma_0^2}\\right)\n",
    "\\end{align} -->\n",
    "\n",
    "* There are many conjugate prior relationships, e.g., Bernoulli-Beta, Gausian-Gaussian, Gaussian-Inverse Wishart, Multinomial-Dirichlet.\n",
    "\n",
    "* Conjugate prior relationships play an important role for online **updating** our prior distribution.\n",
    "\n",
    "* In an online model estimation scenario, where we the posterior has the same form as the prior, we can use the posterior as our new prior. This new prior is now data informative and will update it's parameters based on (1) our initial choice, and (2) the data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
