{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4 - Model Selection and Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last class we introduced **linear regression** with polynomial features and discussed the different system components.\n",
    "\n",
    "Let $\\{(x_i,t_i)\\}_{i=1}^N$ be a set of training data samples, where each sample $x_i$ and target $t_i$ are continuous-valued, i.e. $x_i, t_i \\in\\mathbb{R}$.\n",
    "\n",
    "1. **Feature Space:** we can create a *deterministic* set of features with, for example, polynomials:\n",
    "\n",
    "$$\\phi(x_i) = \\left[1, x_i, x_i^2, \\dots, x_i^{M-1}\\right]^T$$\n",
    "\n",
    "Each data sample $\\{x_i\\}_{i=1}^N$ will have its own representation, and so we can build a **data matrix** (or feature matrix) of size $N\\times M$:\n",
    "\n",
    "$$\\mathbf{X} =\\left[\\begin{array}{c} \\phi(x_1)^T \\\\ \\phi(x_2)^T \\\\ \\vdots \\\\ \\phi(x_N)^T \\end{array}\\right]  = \\left[\\begin{array}{ccccc}\n",
    "1 & x_{1} & x_{1}^{2} & \\cdots & x_{1}^{M-1}\\\\\n",
    "1 & x_{2} & x_{2}^{2} & \\cdots & x_{2}^{M-1}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "1 & x_{N} & x_{N}^{2} & \\cdots & x_{N}^{M-1}\n",
    "\\end{array}\\right]$$\n",
    "\n",
    "2. **Mapper**: a linear combination of features weighted by a set of parameters $\\mathbf{w}=\\left[w_0, w_1, w_2,\\dots, w_{M-1}\\right]^T$, taking the form\n",
    "\n",
    "$$y = f(\\phi(x),\\mathbf{w}) = \\sum_{j=0}^{M-1} w_j\\phi_j(x)$$\n",
    "\n",
    "or, in matrix form,\n",
    "\n",
    "$$y = f(\\phi(x),\\mathbf{w}) = \\mathbf{X}\\mathbf{w}$$\n",
    "\n",
    "3. **Objective Function**: function that assesses the *quality* of the output of the model, for example, an error-based function such as L2-norm of the error or the mean-squared error (MSE) function:\n",
    "\n",
    "$$J(\\mathbf{w}) = \\frac{1}{2N} \\sum_{n=1}^N \\left(t_n - f(\\phi(x_n),\\mathbf{w})\\right)^2 = \\frac{1}{2N}\\left\\Vert \\mathbf{t} - \\mathbf{X}\\mathbf{w} \\right\\Vert^2_2$$\n",
    "\n",
    "4. **Learning Algorithm**: an algorithm that solves or searches for the *optimal* values of the parameters $\\mathbf{w}$ that optimize the objective function. It solves the following optimization problem:\n",
    "\n",
    "$$\\arg_{\\mathbf{w}}\\min J(\\mathbf{w})$$\n",
    "\n",
    "This is the **least mean squares (LMS)** function.\n",
    "\n",
    "Because the selected model is linear on the parameters, we can solve for a solution analytical without having to resort to search algorithms such as the gradient descent.\n",
    "\n",
    "Therefore, the solution for the parameters $\\mathbf{w}$ is the one that solves the equation\n",
    "\n",
    "$$\\frac{\\partial J(\\mathbf{w})}{\\partial\\mathbf{w}}=0$$\n",
    "\n",
    "We can use calculus algebra to take this derivative and solve for $\\mathbf{w}$ (see Lecture 3 notes for this approach), or we can refer to our knowledge of statistics. Recall that the want the output $\\mathbf{y}$ to be as close as possible to the target response $\\mathbf{t}$, therefore, we are solving for $\\mathbf{w}$ using the following equation:\n",
    "\n",
    "$$\\mathbf{t} = \\mathbf{X}\\mathbf{w}$$\n",
    "\n",
    "But, note that $\\mathbf{X}$ is a tall matrix (usually - and ideally - $N>>M$), so we **cannot** just that the left-inverse of $\\mathbf{X}$.\n",
    "\n",
    "This is the problem of finding the best line (or curve) that fits a set of points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "image/png": {
       "width": 400
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image('figures/LeastSquares.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From your statistics course, you learned a solution to this problem: the **least squares solution**, which provides us with an analytical solution for $\\mathbf{w}$, the $\\mathbf{w}^*$:\n",
    "\n",
    "$$\\mathbf{w}^* = \\mathbf{X}^{\\dagger}\\mathbf{t}$$\n",
    "\n",
    "where $\\mathbf{X}^{\\dagger}$ is the pseudo-inverse of the tall matrix $\\mathbf{X}$ and can be computed as\n",
    "\n",
    "$$\\mathbf{X}^{\\dagger} = \\left(\\mathbf{X}^T\\mathbf{X}\\right)^{-1}\\mathbf{X}^T$$\n",
    "\n",
    "**This completes the training stage.** For any given input data, we can compute its polynomial representation and find a solution for $\\mathbf{w}$:\n",
    "\n",
    "$$\\mathbf{w}^* = \\mathbf{X}_{\\text{train}} ^{\\dagger}\\mathbf{t}_{\\text{train}}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$y_{\\text{train}} = \\mathbf{X}_{\\text{train}}\\mathbf{w}^*$$ \n",
    "\n",
    "In the **testing stage**, for any point we first component its polynomial representation, and then use the trained model (essentially the optimal set of parameters $\\mathbf{w}^*$) to compute a prediction for that point:\n",
    "\n",
    "$$y_{\\text{test}} = \\mathbf{X}_{\\text{test}}\\mathbf{w}^*$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Implementation\n",
    "\n",
    "**What can you control?** \n",
    "\n",
    "<!-- * Model order $M$\n",
    "* Feature representation or *basis functions* -->\n",
    "\n",
    "How would you implement linear regression using polynomial features?\n",
    " * Let's see with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Curve Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Suppose Input Data is sampled from a (noisy) sine curve \n",
    "\n",
    "Suppose our data comes from a noisy sinusoidal: $t = \\sin(2\\pi x) + \\epsilon$ where $\\epsilon$ is a (univariate) Gaussian zero-mean random noise. \n",
    "\n",
    "* The univariate Gaussian Distribution is defined as:\n",
    "$$\\mathcal{N}(x | \\mu, \\sigma^2) = \\frac{1}{(2\\pi \\sigma^2)^{1/2}} \\exp\\left\\{ - \\frac{(x - \\mu)^2}{2\\sigma^2}\\right\\}$$\n",
    "\n",
    "where $\\mu$ is the mean and $\\sigma^2$ is the variance. \n",
    "\n",
    "* If the noise is zero-mean Gaussian distributed, it is like we are saying there is a Gaussian around the true curve: \n",
    "\n",
    "$$t = y + \\epsilon$$\n",
    "\n",
    "Let's generate data from the *true* underlying function (which, in practice, we would not know)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoisySinusoidalData(N, a, b, sigma):\n",
    "    '''Generates N data points in the range [a,b) sampled from a sin(2*pi*x) \n",
    "    with additive zero-mean Gaussian random noise with standard deviation gVar'''\n",
    "    # N input samples, evenly spaced numbers between [a,b) incrementing by 1/N\n",
    "    x = np.linspace(a,b,N)\n",
    "    # draw N sampled from a univariate Gaussian distribution with mean 0, sigma standard deviation and N data points\n",
    "    noise = np.random.normal(0,sigma,N) \n",
    "    # desired values, noisy sinusoidal\n",
    "    t = np.sin(2*np.pi*x) + noise\n",
    "    return x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate input samples and desired values\n",
    "\n",
    "N = 50 # number of data samples\n",
    "a, b = [0,1] # data samples interval\n",
    "sigma_train = 0.3 # standard deviation of the zero-mean Gaussian noise\n",
    "sigma_test = 0.1\n",
    "x_train, t_train = NoisySinusoidalData(N, a, b, sigma_train) # Training Data - Noisy sinusoidal\n",
    "x_true, t_true = NoisySinusoidalData(N, a, b, 0) # True Sinusoidal - in practice, we don't have the true function\n",
    "x_test, t_test = NoisySinusoidalData(20, a, b, sigma_test) # Test Data - Noisy sinusoidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(x_train, t_train, c='b',linewidths=3,  label = 'Training Data')\n",
    "plt.plot(x_true, t_true, 'g', linewidth=3, label = 'True Sinusoidal')\n",
    "plt.scatter(x_test, t_test,c='r', marker='*',linewidths=3, label = 'Test Data')\n",
    "plt.legend()\n",
    "plt.xlabel('Data Samples, x')\n",
    "plt.ylabel('Desired Values, t');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us implement linear regression with polynomial features or **polynomial regression**.\n",
    "\n",
    "Before build this function, let's take a look at some strategies to create the **data matrix** $\\mathbf{X}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model Order\n",
    "M = #select a model order\n",
    "\n",
    "# Find the parameters that fit the noisy sinusoidal\n",
    "w, y_train, error = PolynomialRegression(x_train,t_train,M) \n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(x_train,t_train, c='b',linewidths=3, label='Training Data')\n",
    "plt.plot(x_train,y_train,'r--', linewidth=3,label = 'Estimated Polynomial')\n",
    "plt.plot(x_true,t_true,'g',linewidth=3, label = 'True Function')\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Data Samples, x',size=15)\n",
    "plt.ylabel('Desired Values, t',size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "* What happens when the polynomial model order $M$ increases/decreases?\n",
    "\n",
    "* How large/small do the weight parameter values are as we increase $M$? Could this information be useful?\n",
    "\n",
    "* Which model order $M$ works best? Which $M$ would you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# To be finished in class\n",
    "\n",
    "plt.ylabel('Weight values', size=15)\n",
    "plt.xticks(np.arange(len(w)), ['$w_{'+str(i)+'}$' for i in range(len(w))],rotation=0, size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well does this trained model **generalize** to the test data, to which we do not have labels.\n",
    "\n",
    "- In this synthetic environment, we have the label values for the test samples. But in practice, we will **not** have labels for the test data.\n",
    "\n",
    "**Testing Stage**\n",
    "* Apply the same feature extraction as in training: $\\mathbf{X}_{test}$, where $\\mathbf{X}_{test}$ is a $K\\times M$ data matrix\n",
    "* Predict the output using the learned parameters $\\mathbf{w}^*$, that is, $\\mathbf{y}_{test} = \\mathbf{X}_{test}\\mathbf{w}^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Predict Labels.** In this step, we will use the trained model (the vector of coefficients $\\mathbf{w}^*$ and compute the predicted labels for the feature representation of the test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be finished in class: Predict output for test samples\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(x_train,t_train,c='b', linewidths=3, label='Training Data')\n",
    "plt.plot(x_train,y_train,'r--', linewidth=3, label = 'Estimated Polynomial')\n",
    "plt.plot(x_true,t_true,'g', linewidth=3, label = 'True Function')\n",
    "plt.scatter(x_test,t_test,c='r', marker='*', linewidths=3, label = 'Test Data')\n",
    "plt.plot(x_test,y_test,'m--',linewidth=3, label = 'Predictions')\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Data Samples, x',size=15)\n",
    "plt.ylabel('Desired Values, t',size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "* How did the trained model *fit* in the test data?\n",
    "* Is it able to *generalize*?\n",
    "* Can we **design** a *training* strategy that can tells us how *well* we are performing in *unseen and unlabeled* data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What happens when the test points fall outside the range of what the model has *learned*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 4\n",
    "w, y, error = PolynomialRegression(x_train,t_train,M) \n",
    "\n",
    "x_test2, t_test2 = NoisySinusoidalData(20, 0, 1.5, 0.1)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(x_train, t_train, c='b', linewidths=3, label = 'Training Data')\n",
    "plt.plot(x_true, t_true, 'g', linewidth=3, label = 'True Sinusoidal')\n",
    "plt.scatter(x_test2, t_test2, c='r', marker='*',linewidths=3, label = 'Test Data')\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Data Samples, x',size=15)\n",
    "plt.ylabel('Desired Values, t',size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# To be finished in class: Predict output for test samples\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(x_train,t_train,c='b', linewidths=3, label='Training Data')\n",
    "plt.plot(x_train,y_train,'r--', linewidth=3, label = 'Estimated Polynomial')\n",
    "plt.plot(x_true,t_true,'g', linewidth=3, label = 'True Function')\n",
    "plt.scatter(x_test2,t_test2,c='r', marker='*', linewidths=3, label = 'Test Data')\n",
    "plt.plot(x_test2,y_test2,'m--',linewidth=3, label = 'Predictions')\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Data Samples, x',size=15)\n",
    "plt.ylabel('Desired Values, t',size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How do we select the *best* model order? - Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the **Least Mean Squares (LMS)** objective function as a function of the model order $M$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_train = []\n",
    "J_validation = []\n",
    "Mrange = 18\n",
    "\n",
    "for M in range(1,Mrange):\n",
    "    \n",
    "    # To be finished in class\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "plt.plot(list(range(1,Mrange)),J_train,'bo-', label = 'Training')\n",
    "plt.plot(list(range(1,Mrange)),J_validation,'r*-', label = 'Validation')\n",
    "plt.title('Cross-Validation',size=15)\n",
    "plt.xlabel('Model order, $M$',size=15)\n",
    "plt.ylabel('$J(\\mathbf{w})$',size=15)\n",
    "plt.legend(fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Example\n",
    "\n",
    "Let's take a look at COVID-19 data from the state of Florida. Data obtained from the [CDC COVID Data Tracker](https://covid.cdc.gov/covid-data-tracker/#trends_dailytrendscases) on August 29, 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(cases)\n",
    "plt.xlabel('Days', size=15)\n",
    "plt.ylabel('Cumulative Total Cases', size=15)\n",
    "plt.xticks(range(0,len(cases),50), date[range(0,len(cases),50)],rotation=30,size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# To be finished in class\n",
    "\n",
    "plt.xlabel('Days', size=15)\n",
    "plt.ylabel('Cumulative Total Cases', size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit a **polynomial regression** model that predicts the number of daily new cases of COVID-19 in Florida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the optimal set of parameters for the foam height model for each brand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = ##choose model order\n",
    "\n",
    "w, y, e = PolynomialRegression(x, t, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model Coefficients: w=',w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x, t,'-o', label='data')\n",
    "plt.plot(x, y, 'r', label='Estimated Model')\n",
    "plt.xlabel('Days', size=15)\n",
    "plt.ylabel('New Cases', size=15)\n",
    "plt.legend(fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the predicted daily new cases for the next 3 days?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = PolynomialRegression_test(np.array([90,91,92]), M, w)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x, t,'-o', label='data')\n",
    "plt.plot(x, y, 'r', label='Estimated Model')\n",
    "plt.scatter([90,91,92], prediction, marker='*',c='r')\n",
    "plt.xlabel('Days', size=15)\n",
    "plt.ylabel('New Cases', size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "* We did not encode any type of physical behavior into the model, (for example, enforcing the cumulative number of new cases to be the same or larger than the previous day), the model is not able to transcribe them.\n",
    "\n",
    "* The prediction point falls outside the region in which the model was trained and therefore the predictions might not be reliable. We can compute confidence intervals to access our confidence in these predictions.\n",
    "\n",
    "* The **model choice** also plays an important factor in the prediction. What if we considered an exponential model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "#To be finished in class\n",
    "\n",
    "plt.xlabel('Days', fontsize=15)\n",
    "plt.ylabel('New Cases in log-scale', fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have transformed the desired label as its logarithm, our goal is to fit a linear model to approximate:\n",
    "\n",
    "\\begin{align}\n",
    "w_0 + w_1\\mathbf{x}+\\dots+w_M\\mathbf{x}^M &= \\ln(t) \\\\\n",
    "\\iff e^{w_0 + w_1\\mathbf{x}+\\dots+w_M\\mathbf{x}^M} &= t\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 3\n",
    "\n",
    "w_log, y_log, e_log = PolynomialRegression(x, t_log, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x, t,'-o', label='data')\n",
    "\n",
    "#To be finished in class\n",
    "\n",
    "plt.xlabel('Days', fontsize=15)\n",
    "plt.ylabel('New Cases', fontsize=15)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_exp = np.exp(w_log[0] + w_log[1]*np.array([90,92,92]) + w_log[2]*np.array([90,91,92])**2)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x, t,'-o', label='data')\n",
    "plt.plot(x, np.exp(w_log[0] + w_log[1]*x + w_log[2]*x**2), 'c', label='Exponential Model')\n",
    "plt.scatter([90,92,92], pred_exp, marker='*',c='c')\n",
    "plt.xlabel('Days', fontsize=15)\n",
    "plt.ylabel('New Cases', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitative comparison of both models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x, t,'o', label='data')\n",
    "plt.plot(x, y, 'r', label='Polynomial Model')\n",
    "plt.plot(x,  np.exp(w_log[0] + w_log[1]*x + w_log[2]*x**2), 'c', label='Exponential Model')\n",
    "plt.scatter([90,92,92], pred_exp, marker='*',c='c')\n",
    "plt.scatter([90,92,92], prediction, marker='*',c='r')\n",
    "plt.xlabel('Days', fontsize=15)\n",
    "plt.ylabel('New Cases', fontsize=15)\n",
    "plt.legend(fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
